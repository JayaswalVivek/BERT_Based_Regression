This repository contains the code for using DistilBERT for a language-model based regression task. The regression task relates to a Kaggle challenge (CommonLit Readability Prize) and the input data sets can be downloaded from Kaggle.

RMSE value on Kaggle dashboard: 0.606
