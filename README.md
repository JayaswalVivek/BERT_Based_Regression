<h3> DistilBERT for performing a reading comprehension task. </h3>
<b> Data Source: Kaggle </b> </br>
<b> URL: https://www.kaggle.com/competitions/commonlitreadabilityprize</b> </br>
<b> Problem Definition: Rate the complexity of literary passages for grades 3-12 classroom use </b> </br>
<b> Problem type: Regression using unstructured data </b> </br> </br>

An implementation of DistilBERT for Kaggle's "CommonLit Readability Prize" challenge. The source data sets can be downloaded from Kaggle's website.

**RMSE (as per Kaggle dashboard): 0.606**
