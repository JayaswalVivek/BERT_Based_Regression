This repository contains the code for using DistilBERT for a language-model based regression task. The regression task relates to a Kaggle challenge (CommonLit Readability Prize) and the input data sets can be downloaded from Kaggle.

Validation Data RMSE (as per Kaggle dashboard): 0.606
